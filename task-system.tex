\section{Task 2: Integrating with existing state-of-the-art network systems}



So that was task number one, we now move on to task number two, which is actually building the system. It has number two, we split our task in three different in rather two different sub tasks. One is integrating with the existing system. Basically just, you know, how to stick our part into existing network systems. And number two would be to have an error correction mechanism. So let's start with at number one, how to integrate with existing systems. So we'll build a dashboard that would integrate with an existing network controller. With addition network controller, this could be in the form of open a software defined network controller, or it could be in the form of a switch, you know, switch API. What this dashboard does is that based on the user description, we translate this human description, you know, ated, with our cat annotations, into a set of rules that we sent to a switch or an open or or software defined network controller, essentially, our we will design system to be modular in nature. So that we are hardware agnostic, you could work on software defined network work on general switches. In our case, we run the Cisco switch and then we can use Cisco's API to define the set of rules for example, in this case, enabling this physics researcher coming from this walport to contact a particular you know, IP address in the Department of Energy network. So this is the part about translating users findings, users annotations into user specifications into a set of rules. Actually, one thing I forgot to mention is that how would users enter this in the first place? So on our dashboard, we will have we will have annotations of existing flows from two sources one from our measurement in task one VI and two we will generate on the fly. But there are some challenges in generating flows in the front end clustering flows on the fly for example, when you say talk to a department energy server, there could be multiple servers or it could be on behind the content delivery network. So we will have to basically have a way to infer that you know, this set of IP addresses all belong to department energy. There are few ways to do it. Number one is still cat Whois information or the ASN autonomous system. Information. Number two is looking at domain name. Sometimes we can, you know, we have an alternative process that would translate domain will visit the website and domain name. And then we can use techniques like topic modeling to infer that, hey, this website is actually related to Department of Energy. And thus, you know, the user is really indeed talking to Department of Energy. So we can have these labels, available annotations, ultimately annotations available in the dashboard so that users can select that this is indeed their intended destination. Then once we have intended destination, the dashboard will translate this user selection into rules, which will push onto switches, basically, we have a module for different kinds of switches. If it's a Cisco switch, we will say translate these set of rules into Cisco, iOS Ng, something like that API, which will write two switches. And if this is a software defined network, will just will translate in the appropriate API's. So that's pretty much a task to a implementing the dashboard, providing a way to cluster traffic that will annotate for the users the users know what's, what they're selecting, and then translating user selection into actual rules on switches. The problem is that this process, in this process, users can make a mistake and make mistakes. As much as we try or we make mistakes, as much as we try to, you know, annotate destinations for user select, we might make a we might be wrong, or, you know, the user may be too broad in their selection in the whitelist, in the allow list, so the user may have accidentally included more destinations than needed, by the way, for for to a in a case of in case the users computers are compromised themselves. One can argue that a an abt an advanced participant a threat, could in theory, manipulate the dashboard and change the settings. So one way is that we will require a second factor authentication to for the user to use this dashboard to minimize the probability of an automatic manipulation of the dashboard. Of course, we will not deal with cases of rogue users who knowingly know that they're abusing a network that is beyond the scope of this paper, rogue users something that that we don't want to handle in this case. In any case, that was a task to a per task to be our role is to catch errors by users, or errors by our annotations, you know, there's that might be too broad in the definition of allow lists. So basically, what we do is that we would mirror the traffic from the port into exeat instance, which rights flow information to through Kafka to a Spark cluster. And we will run isolation forest algorithms or any other anomaly detection algorithms to find anomalies, we will also match this traffic against existing IP based blacklist or domain based blacklist such as so and so to make sure that users have not or we have not accidentally allow traffic that is going to known IP blacklist or domain blacklist, you know, in the case of command and control of malware. And also somewhere that is, you know, out of anomaly. So we have that mechanism to you know, fix these. And when we detect such anomalies, we will also, you know, automatically, you know, degrade the traffic back to the slow path and notify the user that anomaly has been found, and we let them make a decision as to what's going on as to you know, tell us that we are wrong, or tell us that, you know, they are wrong, or you know, defer this to a network administrator for further decisions. So we call this first process, the user in the loop process, where we don't know we ask the user or ask the user to defer to sis admins. And then through this, through this feedback cycle. We basically conduct reinforcement learning to help better train our anomaly detection mechanism, by the way, an anomaly detection system It also takes features from, you know, various sources such as the endpoint, for example, logs, server logs from users, user input, etc. so as to be catching errors. So, basically, from tasks to a and to B, we will be able to build a system that integrates with existing network and number to catch potential mistakes from our automatic annotation or from the user's decision, the users action.








\paragraph{Modular design for the controller}

System design. see figure 1. How proposed technique will augment existing state-of-the art

// From Rob: // Remove SDN. Write rules to switches. SDN Controller -> Management application (e.g., talk to switch API (cisco iOS ng API for cisco switches and routers)  to set up rules; time-based rules on supported switches if our control plane dies); Ansible Tower, AWX; push configurations to switches (which run SONIC)

// make this system modular; what if the school uses palo alto -> they can switch out the necessary code




\paragraph{Backup system} Zeek as IDS
%https://docs.zeek.org/en/v3.0.14/scripts/policy/frameworks/files/detect-MHR.zeek.html
matching against signatures

defer to existing literature on detecting anomalies with zeek
% https://medium.com/hootsuite-engineering/anomaly-based-intrusion-detection-system-using-machine-learning-a18e88694ce0

Failure modes. what if the user fails to make a right selection? IDS on zeek would help.

Check against known blocklists (IPs, domains).


Anomaly detection:
FlowLens: Enabling Efficient Flow Classification for ML-based Network Security Applications




\paragraph{Human feedback loop}

Are you sure? Anomalous flow?

reinforcement learning



We can't catch cases where the user is a rogue researcher.


\paragraph{Expected outcome} A full fledged small portion of the HSRN that runs the above system for testing purposes.

\paragraph{Lead investigator} PI Huang and Co-PI Pahle will work together on implementing. Co-PI Cappos will advise on XXX.
